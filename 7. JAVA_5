Creating and Destroying Objects
Consider static builders
They can have any name, thus can have multiple methods with same parameters (unlike constructors)
They can return cached objects (eg: Boolean.valueOf)
They can return their subtype, even class objects which are not public. Eg: Collection has 32 factory methods, return type of many are non-public classes. Ofcourse, the interface they extend is public. Returning such interface backed classes, also help in returning specific type based on argument. Eg: EnumSet returns RegularEnumSet or JumboEnumSet based on the argument. In future, JDK can add more types, without client/caller knowing about them. See service interface pattern below
They can reduce verbosity of parameterized types. Eg: Maps.newHashMap()
Service Interface Pattern
Here same pattern as above, where the implementation classes are not even known upfront.
Example: JDBC connection driver classes. DriverManager.registerDriver, and DriverManager.getConnection.
It needs to provide, registration API and then get service API
Cannot subclass and take advantage of constructors. Though this enforces Composition instead of inheritance, so its not so bad.
Cannot easily distinguish between constructing methods, and other methods. Need to use some convention to make it easy. Eg: newInstance, valueOf, of etc.
Builder pattern
When too many parameters use builders instead.
In Builders, each parameter setting can be through a good name method. In constructor its difficult to remember.
Can easily add optional parameter support.
Singleton with private instance or enum
static final variable (also provides init guarantee)
Lazy loading (double checked)
Enums (by default lazy, and provides init guarantee)
Private Constructor
Avoid creating unnecessary objects
Eg: Sring abc = new String("some value"); instead use String abc = "some value";
Choose primitives over boxed, check for unnecessary boxing and unboxing
Clear memory references
Let objects go out of scope quickly
If not, nullify reference (eg: Stack.pop, within method, elements[size] = null)
Check caches and message listeners, they hold references
Avoid finalizers
JVM does not guarantee they will be called
If called, they can be called anytime, not immediately after object is eligible for GC
Never release resource in finalizer, if it does not run, the resource will still be lock (or in inconsistent state)
Hampers performance
Instead use explicit close methods like OutputStream, java.sql.Connection etc
These classes also use finalizers, but that is safety net

Methods common to all objects
equals
If super class has implemented equals, then its okay to not implement (eg: Set used AbstractSet)
Reflexive (equal to self), transitive, symmetric, consistent (unless modified)
Maintain Liskov Substitution Principle, within equals (don't check o.getClass() == this.getClass() instead check with instanceof
Consistent - Don't use external resources (eg: IP address)
hashcode
every class which overrides equals must have it
Consistent across multiple calls
Dont use any fields, which are not used for equals
You can exclude redundant fields (ones which are always same for all objects)
You can cache the hashcode and return that (like String class), but then need to track if value is modified.
toString
clone
Cloneable interface. Its a mixin interface. Does not have clone method.
Object class's clone method is protected
Atypical - Presence of Colenable modifies behavior of Object.clone() behavior. If present it returns object which is field by field copy, and if not present, then .clone method throws CloneNotSupportedException
Cloning is not done using constructor
If you override clone do return super.clone(), if all classes do that up the chain, then Object.clone will be called and you will get the right copy
This is important because spec doesnt enforce anything from Cloneable interface. So someone might override clone and not clone, nor call super.clone, causing problems
Note: Objects.clone() creates a shallow copy
If you override and write clone, ofcourse you cannot set final field, thus need to remove final modifiers
Object's clone method is declared to throw CloneNotSupportedException, but overriding clone methods can omit this declaration.
Like constructor, clone method should not call non-final methods, because super object might not be properly constructed yet, causing some data corruption
Clone method must be synchronized in case of concurrency
In short, you are better off, creating and using a copy-constructor
comparable
Opposing sign for symmetry x.compareTo(y) == -y.compareTo(x)
If compareTo returns 0, objects should ideally be equal (but thats not in contract)
Weird: Inserting new BigDecimal("1.0") and new BigDecimal("1.00") in HashSet stores 2 elements (they use equals), while TreeSet stores only 1 element (they use compareTo)
Classes and Interfaces
Accessibility
Make fields, classes etc as much inaccessible as possible (private, protected, package, then public)
Anything that is public is now part of API, thus difficult to make private later
Private fields with accessor methods
Helps in validating inputs (setters)
Helps in returning copies in outputs (getters)
Make fields as much immutable as possible
Immutable objects are simple
They are thread-safe
They can be shared freely
They can expose their internals
Can take advantage of cached hashCode & lazyInit hashCode
Only disadvantage is memory use
Composition over inheritance
Inheritance violates encapsulation, if super class changes sub-class behavior changes even if its not touched
Super class can later add method, sub-class havent thought of
In fact, it can add method which mutates the state which sub-class never promised to do.
If you add your own methods in sub-class, and later super-class adds same name method its a problem. Either it may not compile based on return type, or contract of that method in super might be different than subclass method.
Instead use composition and forward/delegate the calls
Such classes are called Wrapper classes (decoration pattern)
Only problem is library/frameworks do not know of your class type, and can't trigger message callbacks and such.
Override in inheritance
Constructor must not call method (which is overridden), because super() constructor will call override() of subclass, which is not yet constructed
Same problems can occur with clone and readObject (so avoid inheritance with Cloneable and Serializable)
Prefer interfaces to abstract classes
Classes can be retrofitted to have more interfaces
Interfaces allow mix-in types (markup), without need to implement any methods
Interfaces allow cross-types (eg: SingerWriter implements Singer, Writer)
Interfaces are not allowed methods, but Skeleton types can be created. Eg: AbstractSet, AbstractList etc. These classes help create concrete implementations by providing part of functionality
If class cannot extend Skeletal (Abstract) class, we can implement the Interface, and have Skeletal class instance as composition field, and delegate all interface methods, to skeletal class instance. This is called, simulated multiple inheritance.
Disadvantage: Once release, interfaces are impossible to change (all implementations need to be updated)
Class hierarchies over tagged classes
Lot of boilerplate in tagged classes: Enums, fields, switch statements
Memory issue: Tagged classes can contains fields specific for one type, but object of all types will have those extra fields.
Function objects to represent strategies
Use classes (stateless) to represent computation. This can be passed around. Ex: StringLengthComparator
Favor static member class over non-static
Every non-static class object has instance of enclosing class. Takes more memory.
Non-static class instances cannot be created without creating instances of enclosing class
Though one valid use of non-static class is, implementing Iterator for the class
Static classes are typically used to create Helper classes
Defining them public or private depends on whether you want to expose it in API


Generics
Don't use Raw types
Using types in all reference variables, helps in safety and avoiding boilerplate of casting
Use generic fields (public E element) in class
Use generic methods (public static Set union(Set s1, Set s2)).. helps in type inference
Prefer Lists to arrays
Arrays are covariant (Object[] a = new Long[]), but it fails at runtime (a[0] = "string value");
Arrays retain types at runtime (reified) thus they throw ArrayStoreExceptions. Lists (generics) do type erasure at compile time.
Enums and Annotations
Enums instead of int constants
Enums provide name space. If you use int constants for 2 different Type hierarchies (AppleTypes & OrangeTypes), you can pass value of one to method of another, accidently, and compiler wont complain
Enums are iterable. Cannot iterate over int constants
Enums have default toString. Cannot sysout int constants (they will print numbers which are not helpful)
You can extend functionality of enums
Enums can be based on multiple fields
EnumSet instead of Bit set (way to define union of types eg: STYLE_BOLD | STYLE_ITALIC), instead just use EnumSet.of(STYLE_BOLD, STYLE_ITALIC).
EnumMap
Prefer annotations over naming patterns
Eg: @Test instead of all method names starting with test
Annotations have retention policy. Eg: RetentionPolicy.RUNTIME
Annotations have target. Eg: @Target(ElementType.METHOD)


Methods
Definition
Choose method names carefully - they are part of API
Choose parameter types as interfaces instead of implementations
Long list of methods with identically typed parameters is wrong
Dont have too many parameters
Prefer Enum over boolean
Var args
If method needs to take 1 or more, then have 1st param, then 2nd as var..args
Arrays.asList() was a mistake, because you can pass multiple values to it, but if you pass array to it, then it considers that as var..args with single element of type array.
Instead it should have had Arrays.gather(T... args) and then return Arrays.asList(args)
Return empty collections instead of null
These return values are iterable
General
Avoid float and double for exact answers use BigDecimal
Avoid boxed, (== does not work), and constant boxing-unboxing consumes CPU
Use StringBuilder instead of direct concatenation
Refer to objects by their interfaces
Use checked exceptions for recoverable conditions, and runtime exceptions for programming errors
Favor standard exception like IllegalStateException, IllegalArgumentException etc
Prefer Executors and Tasks to threads
Prefer concurrency classes instead of wait notify
Use Serializable Judiciously
Like APIs once serialized, then cant change class structure
Increases testing burden (backwards compatible)
Increases security loopholes, because it does not use default constructor
Inheritance based classes should avoid serializable

SOLID principles
S = Single Responsibility - Each class/instance should have only 1 responsibility
O = Open Closed - Objects should be open for extension closed for modification
L = Liskov substitution - Instance objects can be replaced with subtypes without altering correctness
I = Interface Segregation - Multiple specific interfaces are better than big general one
D = Dependency Injection - High level and Low level modules should both depend on abstraction
Other design principles
Code to interface not implementation
Favor composition over inheritance
Encapsulate what changes
Strive for loose coupling between objects
Principle of least knowledge = Talk only to immediate friends

Approach
Clarify assumptions regarding domain - features required
Expected traffic/volume/data (calculate/assume)
Expected frequency or repeated calls - Pre-processing of data (eg: Dictionary)
Constraints - Bandwidth/Latency, CPU/Memory/Disk
Scaling - Vertical / Horizontal(duplicate/load-balancing, key-hash, directory-based, service-based)
Caching - LRU, LFU, Timeouts
Heavy writes - Asynchronous (Task Queues)
Single point of failures
Monitoring/Analytics
Staggered/Back-pressure
Batching/Chunking
Geographic split (behavioral/regulatory)
CDN (static content)
Scalability
Horizontal scaling
Caching
Load balancing
Database replication
Database partitioning
NoSQL
Asynchronous (Job Queues)


Lists
ArrayList
Backed by array (which are co-located in memory), thus fast iteration and get(i) operation.
Slow inserts when the backed array is full and has to double in size.
Fail-fast iterators, which can throw ConcurrentModificationException.
Add is O(n) - When element is added to middle of list, all elements on the right have to be moved.
Use Case - When iterations outnumber number of read/writes.
LinkedList
Chain of nodes referencing each other (doubly linked list).
No co-location of nodes, pointers need to be chased for next element, thus slow iterations and get(i) operation.
Fail-fast iterators, which can throw ConcurrentModificationException.
Implements Queue interface, thus allows offer/pop/peek operations.
Add is O(1) - Adding element in middle of list is just adjusting the node pointers.
Internally uses references (~ to skiplist) to optimize iterations.
Use Case - Lot of inserts in middle of the list.
Operation	ArrayList	LinkedList
get(i)	O(1)	O(n)
add()	O(1) amortized	O(1)
remove(i)	O(n) Remove and move all elements	O(n) Iterate then remove
iterator.remove	O(n)	O(1)
Stack
For stack operations push/pop/peek.
Not used anymore. Recommended to use Deque implementations.
Vector
Synchronized version of list.
Not used anymore. Recommended below mentioned alternatives.


Maps
HashMap
key, value pairs.
Permits a null key, and null values.
Iteration order not guaranteed.
Throws ConcurrentModificationException.
Article detailing implementation.
HashMap implementation details
Backed by array (buckets), array-size is known as table-size.
Position in array = element-hash % table-size.
If elements end up in same bucket, they are added to linked-list (or a balanced red-black tree).
O(1) access (if hashcode properly distributes the values, else O(n) for linked-list & O(log(n)) for tree.
Load factor - 0.75 default, decides when table-size should increase (double).
Bigger load-factor - more space-efficient, reduced speed (due to more elements in same bucket).
Lower load-factor - less space-efficient, more speed (less, ideally 1 element in 1 bucket).
Initial table-size = 16.
LinkedHashMap
Insertion order is retained.
Hashtable
Thread-safe.
Not used anymore, ConcurrentHashMap recommended.
ConcurrentHashMap
Thread-safe.
Fine grained locking called striped locking (map is divided into segments, each with associated lock. Threads holding different locks don't conflict).
Improved performance over Hashtable.
TreeMap
Sorted by keys.
Uses Red-Black tree implementation.
ConcurrentSkipListMap
Thread-safe version of TreeMap.
Navigable (floor, ceiling, higher, lower, headSet, tailSet operations).


Queues
LinkedList
Implements Queue interface.
offer, peek, poll operations.
Use case - task queues
ArrayBlockingQueue
Thread-safe.
Backed by array. Thus bounded in size.
Adding element to full queue results in blocking.
Polling an empty queue results in blocking.
Use case - Producer consumer problem.
LinkedBlockingQueue
Thread-safe.
Backed by linked-list.
Optionally bounded in size. Takes maxSize as constructor argument.
ConcurrentLinkedQueue
Thread-safe.
Uses CAS (Compare-And-Swap) for more throughput. Also known as lock free.
Deque classes
ArrayDeque - Double ended queue. Backed by array. Can throw ConcurrentModificationException.
LinkedList - Implements Deque interface.
LinkedBlockingDeque
ConcurrentLinkedDeque
PriorityQueue
Elements sorted based on their natural order (or Comparator provided in Constructor).
Use case - task queues where tasks can have different priorities.
PriorityBlockingQueue
Thread-safe.
DelayQueue
Elements added, are available to be removed only after their delay-time is expired.
SynchronousQueue
Holds single elements.
Blocks for both producer and consumer to arrive.
Use case - For safe/atomic transfer of objects between threads.
equals and hashCode
equals required for all collections.
equals and hashCode required for Maps and Sets (which are backed by Maps).

Collections class
Utility methods
sort(list, key) - guarantees stable sort
reverse
reverseOrder - returns Comparator for reversed order
shuffle
rotate(list, distance) - rotates elements by the distance specified
binarySearch(list, key)
list should be sorted else can get unpredictable results
log(n) if list implements RandomAccess, else O(n)
RandomAccess - Marker interface that says, collection supports fast random access, get(i). Typically backed by arrays.
Methods returning wrapped instances
empty - emptyList, emptySet, emptyMap etc.
synchronized - synchronizedList, synchronizedSet, synchronizedMap etc.
unmodifiable - unmodifiableList, unmodifiableSet, unmodifiableMap etc.
singleton(t) - singleton (returns set), singletonList, singletonMap etc.



Basics
Benefits of Threads
Exploiting multiple processors (Resource utilization) - Increasing core counts
Simplicity of modeling applications - Distinct tasks can have own thread, and each can be written sequentially.
Simplified handling of asynchronous events - If thread is blocked on IO, other threads can still run. Though these days OS allow 100s of thousands of threads, so blocking is not a major issuer anymore. Thus NIO is not as crucial anymore (because its very complicated to implement).
Even if your class doesn't use threads, these do

Underlying frameworks
RMI
JVM (for GC + Main)
Timer
Servlets & JSP
Thread safety
Correctness means that a class conforms to its specification. A good specification defines invariants constraining an object's state and postconditions describing the effects of its operations.

No set of operations performed sequentially or concurrently on instances of a thread-safe class can cause an instance to be in an invalid state.

Race Condition
A race condition occurs when the correctness of a computation depends on the relative timing or interleaving of multiple threads by the runtime
Occurs usually with check-then-act (check stale value). Eg: Lazy initialization.
Data races is different than race condition. Data races is when thread access (read/write) data to variable without any synchronization.
Solutions to compound operations
Atomic classes (if only single variable is the issue)
Synchronized (if multiple variables are to be updated atomically)
Synchronized
Aka Intrinsic locks, Mutexes, monitors
Are re-entrant
Re-entrancy can help for overridden synchronized methods. Call to super.method() tries to re-acquire lock, and is permitted.
Allowing Object class to act as a lock (instead of special classes) was a mistake in JVM design. JVM implementors now have to make trade offs between object size and locking performance.

Liveness and Performance
If scope of synchronized block is too large (say entire method of service). The whole performance benefit of multi-threading might be wiped off if service is accessed by lot of threads.
Scope of synchronized block should be small enough that it covers all mutable state.


Task Execution
Thread Pools
Threadpool with its bounded pool helps throttle the inputs/requests so as to not exhaust available resources.

Single Threaded Executors provide synchronization guarantee that writes made by a task will be visible to subsequent tasks.

Types

newFixedSizeThreadPool - creates new thread, if one dies due to exception
newCachedThreadPool - keeps increasing threads
newSingleThreadExecutor - consumes task based on queue type (FIFO, LIFO, Priority etc), resurrects thread if dead
newScheduledThreadPool - supports delayed and periodic execution similar to Timer
Usually shutdown call is immediately followed by awaitTermination.

Uncaught exception handlers
Thread provides facility for UncaughtExceptionHandler. When thread dies due to some exception, JVM checks if it has exception handler, if not it checks its ThreadGroup, if not then its super ThreadGroup and so on. Final system level ThreadGroup just prints stack trace to System.err

Shutdown hooks
JVM also provides Runtime.addShutdownHook for when it attempts to shut down.
Then it runs finalizers if runFinalizerOnExit is true
It does not attempt to shutdown application threads, they die abruptly
If these hooks do not complete, they hang the JVM. Thus do proper synchronization and not dead lock them.
Daemon threads
Daemon threads do not stop JVM to shutdown
GC, housekeeping threads are daemon threads
Threads inherit daemon status of the owner thread
When JVM halts, they do not call finally for daemon, nor cleanup their stacks, nor call finalizers.
Thus better to use them sparingly
Finalizers
Opportunity given by JVM to reclaim/free any resources being held up
Not guaranteed to run
Avoid as much as possible, catch-finally can more often do better job
Applying Thread Pools
Thread pool sizes
If its too big, it can exhaust memory (& lot of overhead of creating/managing them)
If its too small, not completely utilizing the CPU
Usually, N (number of CPU cores) is right size of pools
Though, if tasks do IO then, not all threads will be schedulable (tasks will be waiting for some resource), so its okay to increase size of threadpool.
int N_CPUS = Runtime.getRuntime().availableProcessors();
Other deciding factors: memory, file handles, socket handles, and database connections
ThreadPoolExecutor
Threads
newFixedThreadPool: corePoolSize == maximumPoolSize
newCachedThreadPool: corePoolSize = 0 and maximumPoolSize = Integer.MAX_VALUE
Keep alive: how long to wait before unused thread is reclaimed (trade off)
Task Queues
newFixedThreadPool and newSingleThreadedExecutor use unbounded LinkedBlockingQueue
Try to use bounded (LinkedBlockingQueue, ArrayBlockingQueue or PriorityQueue)
Saturation Policy
When bounded queue is full, what to do when task is submitted
Abort - throw RejectedExecutionException
Discard - discard silently
Discard oldest - discards oldest from queue
Caller Runs - return task to caller, so that caller thread can run it instead
Thread Factory
Used to create new threads
By default new non-daemon threads are created
Can be overridden to create special threads which do say logging
Avoiding Liveness Hazards
Deadlocks
Database systems are great at handling deadlocks; they back-off certain transactions such that locks are released.
JVM is not so kind. When threads are deadlocked, that's it, game over.
Transfer money is classic examples (with synchronized block on from and to accounts). If 2 calls are made, where 1st case arguments are from then to, and in 2nd case, its to then from. They may deadlock. To solve, either get comparable int keys or System.identityHashcode(), and order which account to be synchronized first. So no matter what's order of arguments, you always lock same account first, avoiding deadlock.


How to avoid

Use only 1 locks (so no ordering issues)
Order locks if multiple (ensure ordering is same no matter order of arguments)
Use tryLock method of lock classes
Starvation and LiveLock
Starvation is when thread is stuck
Livelock is when thread keeps running (eg: message listener throws exception, rolls back then again tries processing of same object)
Performance and Scalability
Amdhal's law - How much a program can be theoretically sped up.

Trick is to divide into multiple tasks with their own data structures, and converge the results (this last step will be only step that will be sequential)

ConcurrentLinkedQueue is twice as fast as synchronizedLinkedList, because former has only final pointer updates as sequential while latter synchronizes on whole list.

Costs on performance
Context switching
Synchronization
Data locality (memory cache)
Blocking on locks
Steps
Reduce lock contention
Reduce scope - get in / get out
Reduce lock granularity (too many times in and out is not good too)
Lock striping
Avoid hot fields
Non blocking (compare-and-swap)
Say no to object pooling - Java is super fast at new allocation, but getting objects from pool requires synchronization
Explicit Locks
Lock and ReentrantLock
Lock implementations must provide the same memory-visibility semantics as intrinsic locks, but can differ in their locking semantics, scheduling algorithms, ordering guarantees, and performance characteristics.

Advantages of lock classes
More flexible. Need not release lock in same block of code unlike synchronized
"Synchronized block" threads cannot be interrupted while they are waiting for lock.
lockInterruptibly can stop waiting for lock on interrupt
Deadlock can be avoided by trying to acquire lock, and releasing already acquired, if cannot acquire new one.
Intrinsic locks can't release locks on timeout
Since Java 6, performance of intrinsic and reentrant lock is very similar. Earlier it used to be slower.
Always do lock.unlock in finally block

Locks can be fair/unfair. Fair locks implement queues to handle requests for a lock. Ofcourse, fairness comes with cost of performance.

Read-Write lock
Allows multiple concurrent readers, but only single writer
Great for data structure with lot of reads
More complex to implement thus slightly slower than reentrant lock
Implementation factors

Release preference - If writer is running, and readers+writers are waiting, preference to writer?
Reader barging - If reader is running, and readers+writers are waiting, preference to reader? Good for throughput but writer can become starved
Reentrancy - Are they reentrant
Downgrading - what if writer lock owners wants only reader lock
Upgrading - What if reader lock owner also wants writer lock
Custom Synchronizer
Conditional queues - Threads waiting for an object lock which reflects certain condition.

Explicit class called Condition for implementing conditional queues (which can be implemented using intrinsic locks too).

Condition is associated with single lock. Lock.newCondition()

Advantages
Fairness in wait
Timeout facility (flexibility)

Consider static builders
They can have any name, thus can have multiple methods with same parameters (unlike constructors)
They can return cached objects (eg: Boolean.valueOf)
They can return their subtype, even class objects which are not public. Eg: Collection has 32 factory methods, return type of many are non-public classes. Ofcourse, the interface they extend is public. Returning such interface backed classes, also help in returning specific type based on argument. Eg: EnumSet returns RegularEnumSet or JumboEnumSet based on the argument. In future, JDK can add more types, without client/caller knowing about them. See service interface pattern below
They can reduce verbosity of parameterized types. Eg: Maps.newHashMap()
Service Interface Pattern
Here same pattern as above, where the implementation classes are not even known upfront.
Example: JDBC connection driver classes. DriverManager.registerDriver, and DriverManager.getConnection.
It needs to provide, registration API and then get service API
Cannot subclass and take advantage of constructors. Though this enforces Composition instead of inheritance, so its not so bad.
Cannot easily distinguish between constructing methods, and other methods. Need to use some convention to make it easy. Eg: newInstance, valueOf, of etc.
Builder pattern
When too many parameters use builders instead.
In Builders, each parameter setting can be through a good name method. In constructor its difficult to remember.
Can easily add optional parameter support.
Singleton with private instance or enum
static final variable (also provides init guarantee)
Lazy loading (double checked)
Enums (by default lazy, and provides init guarantee)
Private Constructor
Avoid creating unnecessary objects
Eg: Sring abc = new String("some value"); instead use String abc = "some value";
Choose primitives over boxed, check for unnecessary boxing and unboxing
Clear memory references
Let objects go out of scope quickly
If not, nullify reference (eg: Stack.pop, within method, elements[size] = null)
Check caches and message listeners, they hold references
Avoid finalizers
JVM does not guarantee they will be called
If called, they can be called anytime, not immediately after object is eligible for GC
Never release resource in finalizer, if it does not run, the resource will still be lock (or in inconsistent state)
Hampers performance
Instead use explicit close methods like OutputStream, java.sql.Connection etc
These classes also use finalizers, but that is safety net
Methods common to all objects
equals
If super class has implemented equals, then its okay to not implement (eg: Set used AbstractSet)
Reflexive (equal to self), transitive, symmetric, consistent (unless modified)
Maintain Liskov Substitution Principle, within equals (don't check o.getClass() == this.getClass() instead check with instanceof
Consistent - Don't use external resources (eg: IP address)
hashcode
every class which overrides equals must have it
Consistent across multiple calls
Dont use any fields, which are not used for equals
You can exclude redundant fields (ones which are always same for all objects)
You can cache the hashcode and return that (like String class), but then need to track if value is modified.
toString
clone
Cloneable interface. Its a mixin interface. Does not have clone method.
Object class's clone method is protected
Atypical - Presence of Colenable modifies behavior of Object.clone() behavior. If present it returns object which is field by field copy, and if not present, then .clone method throws CloneNotSupportedException
Cloning is not done using constructor
If you override clone do return super.clone(), if all classes do that up the chain, then Object.clone will be called and you will get the right copy
This is important because spec doesnt enforce anything from Cloneable interface. So someone might override clone and not clone, nor call super.clone, causing problems
Note: Objects.clone() creates a shallow copy
If you override and write clone, ofcourse you cannot set final field, thus need to remove final modifiers
Object's clone method is declared to throw CloneNotSupportedException, but overriding clone methods can omit this declaration.
Like constructor, clone method should not call non-final methods, because super object might not be properly constructed yet, causing some data corruption
Clone method must be synchronized in case of concurrency
In short, you are better off, creating and using a copy-constructor
comparable
Opposing sign for symmetry x.compareTo(y) == -y.compareTo(x)
If compareTo returns 0, objects should ideally be equal (but thats not in contract)
Weird: Inserting new BigDecimal("1.0") and new BigDecimal("1.00") in HashSet stores 2 elements (they use equals), while TreeSet stores only 1 element (they use compareTo)



Classes and Interfaces
Accessibility
Make fields, classes etc as much inaccessible as possible (private, protected, package, then public)
Anything that is public is now part of API, thus difficult to make private later
Private fields with accessor methods
Helps in validating inputs (setters)
Helps in returning copies in outputs (getters)
Make fields as much immutable as possible
Immutable objects are simple
They are thread-safe
They can be shared freely
They can expose their internals
Can take advantage of cached hashCode & lazyInit hashCode
Only disadvantage is memory use
Composition over inheritance
Inheritance violates encapsulation, if super class changes sub-class behavior changes even if its not touched
Super class can later add method, sub-class havent thought of
In fact, it can add method which mutates the state which sub-class never promised to do.
If you add your own methods in sub-class, and later super-class adds same name method its a problem. Either it may not compile based on return type, or contract of that method in super might be different than subclass method.
Instead use composition and forward/delegate the calls
Such classes are called Wrapper classes (decoration pattern)
Only problem is library/frameworks do not know of your class type, and can't trigger message callbacks and such.
Override in inheritance
Constructor must not call method (which is overridden), because super() constructor will call override() of subclass, which is not yet constructed
Same problems can occur with clone and readObject (so avoid inheritance with Cloneable and Serializable)
Prefer interfaces to abstract classes
Classes can be retrofitted to have more interfaces
Interfaces allow mix-in types (markup), without need to implement any methods
Interfaces allow cross-types (eg: SingerWriter implements Singer, Writer)
Interfaces are not allowed methods, but Skeleton types can be created. Eg: AbstractSet, AbstractList etc. These classes help create concrete implementations by providing part of functionality
If class cannot extend Skeletal (Abstract) class, we can implement the Interface, and have Skeletal class instance as composition field, and delegate all interface methods, to skeletal class instance. This is called, simulated multiple inheritance.
Disadvantage: Once release, interfaces are impossible to change (all implementations need to be updated)
Class hierarchies over tagged classes
Lot of boilerplate in tagged classes: Enums, fields, switch statements
Memory issue: Tagged classes can contains fields specific for one type, but object of all types will have those extra fields.
Function objects to represent strategies
Use classes (stateless) to represent computation. This can be passed around. Ex: StringLengthComparator
Favor static member class over non-static
Every non-static class object has instance of enclosing class. Takes more memory.
Non-static class instances cannot be created without creating instances of enclosing class
Though one valid use of non-static class is, implementing Iterator for the class
Static classes are typically used to create Helper classes
Defining them public or private depends on whether you want to expose it in API


Classes and Interfaces
Accessibility
Make fields, classes etc as much inaccessible as possible (private, protected, package, then public)
Anything that is public is now part of API, thus difficult to make private later
Private fields with accessor methods
Helps in validating inputs (setters)
Helps in returning copies in outputs (getters)
Make fields as much immutable as possible
Immutable objects are simple
They are thread-safe
They can be shared freely
They can expose their internals
Can take advantage of cached hashCode & lazyInit hashCode
Only disadvantage is memory use
Composition over inheritance
Inheritance violates encapsulation, if super class changes sub-class behavior changes even if its not touched
Super class can later add method, sub-class havent thought of
In fact, it can add method which mutates the state which sub-class never promised to do.
If you add your own methods in sub-class, and later super-class adds same name method its a problem. Either it may not compile based on return type, or contract of that method in super might be different than subclass method.
Instead use composition and forward/delegate the calls
Such classes are called Wrapper classes (decoration pattern)
Only problem is library/frameworks do not know of your class type, and can't trigger message callbacks and such.
Override in inheritance
Constructor must not call method (which is overridden), because super() constructor will call override() of subclass, which is not yet constructed
Same problems can occur with clone and readObject (so avoid inheritance with Cloneable and Serializable)
Prefer interfaces to abstract classes
Classes can be retrofitted to have more interfaces
Interfaces allow mix-in types (markup), without need to implement any methods
Interfaces allow cross-types (eg: SingerWriter implements Singer, Writer)
Interfaces are not allowed methods, but Skeleton types can be created. Eg: AbstractSet, AbstractList etc. These classes help create concrete implementations by providing part of functionality
If class cannot extend Skeletal (Abstract) class, we can implement the Interface, and have Skeletal class instance as composition field, and delegate all interface methods, to skeletal class instance. This is called, simulated multiple inheritance.
Disadvantage: Once release, interfaces are impossible to change (all implementations need to be updated)
Class hierarchies over tagged classes
Lot of boilerplate in tagged classes: Enums, fields, switch statements
Memory issue: Tagged classes can contains fields specific for one type, but object of all types will have those extra fields.
Function objects to represent strategies
Use classes (stateless) to represent computation. This can be passed around. Ex: StringLengthComparator
Favor static member class over non-static
Every non-static class object has instance of enclosing class. Takes more memory.
Non-static class instances cannot be created without creating instances of enclosing class
Though one valid use of non-static class is, implementing Iterator for the class
Static classes are typically used to create Helper classes
Defining them public or private depends on whether you want to expose it in API
Generics
Don't use Raw types
Using types in all reference variables, helps in safety and avoiding boilerplate of casting
Use generic fields (public E element) in class
Use generic methods (public static Set union(Set s1, Set s2)).. helps in type inference
Prefer Lists to arrays
Arrays are covariant (Object[] a = new Long[]), but it fails at runtime (a[0] = "string value");
Arrays retain types at runtime (reified) thus they throw ArrayStoreExceptions. Lists (generics) do type erasure at compile time.
Enums and Annotations
Enums instead of int constants
Enums provide name space. If you use int constants for 2 different Type hierarchies (AppleTypes & OrangeTypes), you can pass value of one to method of another, accidently, and compiler wont complain
Enums are iterable. Cannot iterate over int constants
Enums have default toString. Cannot sysout int constants (they will print numbers which are not helpful)
You can extend functionality of enums
Enums can be based on multiple fields
EnumSet instead of Bit set (way to define union of types eg: STYLE_BOLD | STYLE_ITALIC), instead just use EnumSet.of(STYLE_BOLD, STYLE_ITALIC).
EnumMap
Prefer annotations over naming patterns
Eg: @Test instead of all method names starting with test
Annotations have retention policy. Eg: RetentionPolicy.RUNTIME
Annotations have target. Eg: @Target(ElementType.METHOD)
Methods
Definition
Choose method names carefully - they are part of API
Choose parameter types as interfaces instead of implementations
Long list of methods with identically typed parameters is wrong
Dont have too many parameters
Prefer Enum over boolean
Var args
If method needs to take 1 or more, then have 1st param, then 2nd as var..args
Arrays.asList() was a mistake, because you can pass multiple values to it, but if you pass array to it, then it considers that as var..args with single element of type array.
Instead it should have had Arrays.gather(T... args) and then return Arrays.asList(args)
Return empty collections instead of null
These return values are iterable
General
Avoid float and double for exact answers use BigDecimal
Avoid boxed, (== does not work), and constant boxing-unboxing consumes CPU
Use StringBuilder instead of direct concatenation
Refer to objects by their interfaces
Use checked exceptions for recoverable conditions, and runtime exceptions for programming errors
Favor standard exception like IllegalStateException, IllegalArgumentException etc
Prefer Executors and Tasks to threads
Prefer concurrency classes instead of wait notify
Use Serializable Judiciously
Like APIs once serialized, then cant change class structure
Increases testing burden (backwards compatible)
Increases security loopholes, because it does not use default constructor
Inheritance based classes should avoid serializable


SOLID principles
S = Single Responsibility - Each class/instance should have only 1 responsibility
O = Open Closed - Objects should be open for extension closed for modification
L = Liskov substitution - Instance objects can be replaced with subtypes without altering correctness
I = Interface Segregation - Multiple specific interfaces are better than big general one
D = Dependency Injection - High level and Low level modules should both depend on abstraction
Other design principles
Code to interface not implementation
Favor composition over inheritance
Encapsulate what changes
Strive for loose coupling between objects
Principle of least knowledge = Talk only to immediate friends


oncepts
Throughput - Percentage of time application runs vs GC
Latency - Amount of pause time for application waiting for GC to complete
Memory - Amount of memory used to store the objects aka heap (along with GC related data structures)
Trade offs
If memory is less, throughput is less, because JVM has to constantly do GC
If memory is more, latency is high, because JVM has to sweep huge space to do GC
Use cases
For trading applications, deterministic (more average) latency is better than sudden spikes (increased worst case latency).
For batch applications, it might be ok for increase worst case latency, if it helps gain more throughput
Tweaks
To large extent, more memory for GC helps in increasing throughput
Worst case latency can be reduced by keeping heap size small (& live set small)
Frequency of GC can be reduced by managing heap & generation sizes
Frequency of large pauses can be reduced by running GC with application, sometimes at cost of throughput (because it runs longer due to 2 STW pauses, and one thread is used by GC which could've been used by application).
Object lifetimes
Infant mortality / Weak generational hypothesis - Most objects die young.
Thus, generational GC algorithms provide magnitude-of-order better throughput.
How? Region with newly allocated object is sparse for live objects, they can be quickly copied over and region can be wiped entirely.
If application keeps allocating objects that live too long. The generational split becomes useless, and GC takes long time. Because old generation is too big (& not so sparse).
Lifetime of object is recorded by JVM as number of GC cycles survived.
Stop the World Events
Collectors need application execution to stop for practical reasons.
Threads are signalled to stop. Threads stop when they reach safe points of execution.
If thread is busy (copying large array, cloning a large object), it might be few milliseconds till this point.
‑XX:+PrintGCApplicationStoppedTime this flag is used to print the time taken to reach safe point.
Once GC STW event is over, all threads are free to resume. An application with large number of threads can suffer scheduling pressure. It might be more efficient to use different collector then.
Heap organization in HotSpot
Heap is split in Young and Old (Tenured) generation
Young generation is split in - Eden and Survivor (1,2) spaces
PermGen is used to store effectively immortal objects (Classes, static strings etc).
In Java 7, interned Strings were removed from PermGen.
In Java 8, PermGen space itself is replaced by MetaSpace.
Object allocation
Each thread is assigned TLAB (Thread Local Allocation Buffer) to allocate new objects.
Since there is no conflict between threads, object allocation is just a bump-the-pointer, and is faster than MALLOC in C. Roughly 10 machine instructions.
When TLAB is exhausted new TLAB is requested from Eden. If Eden is filled, Minor GC is triggered.
If a large object (size greater than TLAB) is to be allocated, it is done directly in Eden or Old Generation.
-XX:PretenureSizeThreshold=<n> If this is smaller than TLAB, then small objects are still allocated in TLAB itself, not in Old generation.
Minor Collection
Called when Eden is full.
Live objects are moved to one of the survivor spaces.
If survivor space is full or object has live too long (XX:MaxTenuringThreshold=<n>) it is moved to tenured generation.
Major cost of minor collection is in copying live objects to survivor / old generation. Thus, overall cost depends on number of objects to be copied not the size of Eden.
Thus, if new generation size is doubled, total minor GC time is almost halved (thus increasing the throughput). Assuming number of live objects remain constant.
Minor collections are STW events. This is becoming an issue as heaps are getting larger, with more and more live objects.
This algorithm is called mark-and-copy


erial Collector
Smallest footprint of any collectors
Uses single thread for both minor and major collections.
Objects in old gen are allocated with simple bump the pointer technique
Major GC is triggered when old gen is full
Parallel Collector
Parallel Collector - Multiple threads for minor GC, and single thread for major GC.
Parallel Old Collector - Multiple threads for both minor and major GC. Default since Java 7u4
Doesn't run with the application.
Greatest throughput in multi-processor systems. Great for batch applications.
Cost of Old GC, is proportional to number of objects, thus doubling old gen size can help in increasing throughput (larger but fewer GC pauses).
Minor GCs are fast because promotion in old gen is just bump-the-pointer.
Major GC takes 1-5 seconds per live data
Allows for -XX:+UseNUMA to allocate Eden space per CPU socket (can increase performance)
Concurrent Mark and Sweep
Parallel (multiple threads) for Minor GC
Runs with application to try to avoid promotion failure. Promotion failure causes FullGC.
CMS =
Initial mark = Find GC roots
Concurrent mark = mark all objects from GC root
Concurrent pre-clean = check for updated object references & promoted objects during mark (Card Marking technique)
Re-mark = mark all objects in pre-clean
Concurrent sweep = reclaim memory and update free-lists
Concurrent reset = reset data structures used
During concurrent sweep, promotions can occur, but those are in free-lists which are not being swept anyways. So there is not conflict.
Minor GCs can keep happening while Major GC is happening! Thus the pre-clean phase.
Slower minor GCs during promotion. Cost of promotion is higher since, free-lists have to be checked for suitable sized hole.
CMS is not compacting collector, so when object promotion fails due to not having enough space in free-lists. CMS is followed by compaction. This latency can be worse than Parallel Old collector.
Decreases latency, but less throughput. Avg ¼ GC threads per 1 CPU core.
Throughput reduction between 20-40% compared to parallel collector (& based on object allocation rate).
20% more space required.
"Concurrent mode failure" - When CMS cannot keep up with high promotion rates. Increasing heap makes it even worse, because sweeping will take even more time.
G1 Garbage First
Soft real-time targets. Spend x milliseconds in GC out of y milliseconds.
Divides heap into large regions ~2048
Categorizes regions in Eden, Survivor and Old gen spaces.
Minor GC is triggered, when all Eden regions are filled.
Selects closest set of nearly free regions (called Collection Set), to move live objects, essentially causing regions to be empty. Thus it approaches problem incrementally, as opposed to CMS which has to perform on entire Old gen.
Objects larger than 50% of region are saved in "humungous region"
Regions can have objects being referenced from multiple other regions. These are tracked using Reference Sets. Thus, while moving live objects, all the references to such objects need to be updated. Thus, even minor collections can potentially be longer than Parallel or CMS collector.
It avoids collecting (moving) from regions which have high references. Unless it has no other option.
G1 is target driven on latency –XX:MaxGCPauseMillis=<n>, default value = 200ms
G1 reduces worst case latency, at the cost of higher average latency.
Compactions are piggybacked on Young Gen GC.
During reference changes, cards (arrays pointing to 512 bytes of a region) are marked dirty, and source-target details are placed in dirty card queue. Depending on number of elements in queue (white, green, yellow, red) G1 starts threads which take information from queue and write to Remembered Set. More the queue is full, more G1 threads try to drain it. Remembered set will be heavily contended if all threads directly write to RS, its better if only specific G1 threads (1 or 2) write to them.
If Young GC cannot finish within maxTargetPauseTime, then # of Eden regions are reduced to finish within the target.
Old GC is triggered when total 45% is full, and is checked just after Young GC or after allocating humongous object.


Comparators
vehicles.sort(Comparator.comparing(Vehicle::getWheels)); vehicles.sort(Comparator.comparing(Vehicle::getWheels)); vehicles.sort(Comparator.comparing(Vehicle::getWheels).thenComparing(Vehicle:getColor); //chaining

Concurrency
HashMap

compute
computeIfPresent (blocking, so write smaller computations)
computeIfAbsent (blocking, so write smaller computations)
putIfAbsent
merge
getOrDefault (k, def)
Adders/Accumulators

Much more performant than AtomicLong (have single copy across threads). Accumulators, each thread has own copy tracking its own counter, and when retrieval is triggered in any thread, all threads coordinate and perform total sum of all threads’ counts.

Basically no contention, during increment, decrement, add, thus much faster.

LongAdder
DoubleAdder
LongAccumulator
DoubleAccumulator
Operations

increment
decrement
add (long)
sum // retrieves result by coordinating between threads
reset
CompletableFuture
Similar to JavaScript promises. Multiple async tasks can be chained (performed one after another on separate thread). Better alternative to future where the method get is blocking (waits indefinitely for the result). In completableFuture the current thread is not blocked. Each task is executed once previous task is completed.

Also, the program itself becomes more readable.

 CompletableFuture.supplyAsync(() -> getStockInfo(“GOOGL”), executor)   // if executor is not passed it uses internal pool
        .whenComplete((info, exec) -> System.out.println(info))  // triggered once previous operation is finished
        .thenApply(Stock::getRate)   
        .thenAccept(rate -> System.out.println(rate))  
        .thenRun(() -> System.out.println(“done”)));  

So when you trigger this, it immediately returns the CompletableFuture instance, which can be used to check its status and such.

supply method takes Supplier which returns a value
thenApply method argument is Function which takes input and returns value
thenAccept method argument is Consumer which takes input
thenRun method argument is Runnable which only runs
CompletableFuture has no control of tasks while they are running in the executor. So cancel method just sets returned value as Exceptional.
StampedLock
Better alternative for ReadWriteLock
It does optimistic reads so works faster only on less contended operations
Not re-entrant
@Contended
For fields shared within same cache line and if only 1 field in it is volatile, then for multiple threads, the cache line will be flushed and will be updated. Thus use of cache is of no use. To fix this, set the field to hot field by using @Contented so that JVM can pad the field so that it takes entire cache line and is not shared with other fields.

Java Memory Model

What is it?
Specification deciding how JVM can reorder instructions (for performance) aka ensures guaranteed ordering of of reads and writes under certain conditions (happens-before). Every JVM has to implement this spec.
Barriers that forbid reordering instructions (load-load, load-store, store-load, store-store)
Variables
volatile
final = all writes before volatile write will be reflected when/after volatile is read (potentially by other thread). Threads need to use the same volatile variable for this to work. For double/long (which occupy multiple word spaces, word-breakdown is forbidden to ensure integrity of data).
Methods - synchronized
Locks - normal objects used as locks, and lock classes like ReadWriteLock.
Threads - When a new thread is started, it is guaranteed to see all values written before thread started.


JVM Internals
JVM Internals
Some of the topics listed below are tricks JVM uses to improve performance. Subset of these can be exploited to further improve application performance.

Note: These topics are highly unlikely to come up in an interview. Feel free to just glance through without digging deep.

Compressed pointers
32 bit references can address 4GB, while 64 bit can reference 2^64 bytes (though limited by OS/RAM on the machine).
Having 64 bit reference for every object increases memory usage. JVMs use compressed pointers to address this issue.
Basic idea is to store 32-bits per reference and then add to a base address to find final 64-bit address.
Flag: -XX:+UseCompressedOops. Latest versions of 64-bit Java have this argument by default.
Addresses upto 4gb untranslated.
Addresses 4gb to 28gb, remove 3bits, because Java has 8 byte word aligned, thus 3 bits need not be stored.
Important because Java has more references. In C++ memory layout follows struct layout.
Java 8 has JVM args, +XX:ObjectAlignmentInBytes=16 for heap between 32gb and 64gb.
String interning
Interning = storing strings in a pool and re-using them
If you intern a set of all strings, you can compare them by == improving performance.
It is stored internally as a hashmap (it is native C code, not Java code).
More details here and here
How would you implement your own string interning?
private static final WeakHashMap<String, WeakReference<String>> s_manualCache
      = new WeakHashMap<String, WeakReference<String>>(100000);
 
private static String manualIntern(final String str){
    final WeakReference<String> cached = s_manualCache.get(str);
    if (cached != null){
        final String value = cached.get();
        if (value != null)
            return value;
    }
    s_manualCache.put(str, new WeakReference<String>(str));
    return str;
}
Thread Affinity
Makes the thread stick to a CPU core, even if it has no tasks left to perform. Unlike normal threads, this won't go into sleep/wait. Thread performs busy-spin. Note: This is wasting of CPU resources, and it can lead to thread starvation since other threads do not get access to that core. Thus, it needs to be used for the right applications. Helpful in latency critical applications like FX Trading.

Thread affinity only works for Linux and there are Java libraries available to use the same


Communication
What do they look for?

Problem solving skills

How many clarify problem statement
Ask questions and not make assumptions
Mention edge cases
Walk through the problem one thing at a time
Code beautifully (not syntax wise though)
Test the code once code completed and then only say it is done
Working on large systems

How will you design systems
High QPS what will you do
If any issue how do you go about resolving it
System Design
Sample Design questions

Tic Tac Toe
Minesweeper
Web Crawler
TinyURL
Air Traffic Controller
Conference Scheduler

Healthcare data collection by government (Thoughtworks)
